---
title: "lab3"
author: "Jackson Dial"
date: '2023-01-23'
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r}
library(tidyverse)
```


```{r}
#prior parameters
a <- 0.05
b <- 1

#sufficient statistics
N = 30
Sx = 1

#updated parameters
na = a + Sx
nb = b + N - Sx

#Prior, Likelihood, Posterior

theta = c(1:1000)/1000
prior = dbeta(theta, a, b)
posterior = dbeta(theta, na, nb)

ggplot()+
  geom_line(aes(x = theta, y = prior), col = "blue")+
  geom_line(aes(x = theta, y = posterior), col = "red")+
  theme_light()
```


```{r}
#function to calculate the loss
loss_function <- function(t, c){
  if(c > t){
    l = c-t
  }
  if(c<=t){
    l = 10*(t-c)
  }
  return(l)
}
```


```{r}
#Function to calculate the risk
risk_fun <- function(C, a, b, Sx, N, infinity = 1000){
  lenC <- length(C)
  na <- a+Sx
  nb <- b + N - Sx
  theta = rbeta(infinity, na, nb)
  # risk = c()
  # for(j in 1:lenC){
  #   loss = apply(as.matrix(theta),1,loss_function, C[j])
  #   risk[j] <- mean(loss)
  # }
  loss = apply(as.matrix(theta),1,loss_function,c)
  risk = mean(loss)
  # return(risk)
}
```


```{r}
C <- (1:250)/500
risk <- risk_fun(C,a,b,Sx,N)
best <- C(which.min(risk))

ggplot()+
  geom_line(aes(x = C, y = risk))+
  geom_vline(xintercept = best, color = "red")
```



## Sensitivity Analysis

```{r}
A = (1:19)/20
lenA = length(A)
B = rep(1,lenA)

C = (1:250)/500

RISK = matrix(nrow = lenA)
Best = rep(NA,lenA)

#something is wrong with my risk_fun
for(j in 1:lenA){
  risk = risk_fun(C, A[j],B[j],Sx,N)
  RISK[j,]= risk
  Best[j] = C[which.min(risk)]
}
```


```{r}
Risk = data.frame(risk = as.vector(RISK),
                  a = A,
                  c = rep(C,each = nrow(RISK)))
ggplot(Risk, aes(x = c, y = risk, group = a, color = a))+
  geom_line(alpha = 1, size = .1)+
  theme_bw()+
  ggtitle("Risk function for different values of a")

```



```{r}
N = 30
seqSx = 0:30
optimum = matrix(nrow = 3, ncol = 31)


optimum_fun = function(Sx, a, b, N, infinity = 100){
  C = (1:100)/100
  risk = apply(as.matrix(C),1,risk_fun,a,b,Sx,N,infinity = 200)
  return(C[which,min(risk)])
}
a = .05
b = 1

optimum[1,]=apply(as.matrix(seqSx),1,optimum_fun,a,b,N)
optimum[2,]=seqSx/N
optimum[3,]=.1
```


```{r}
plot(seqSx,optimum[1,],
     col = "blue", type = "l",ylim = c(0,1),
     ylab = "resources allocated",
     xlab = "observed number of diseased cases")
par(new = T)
plot(seqSx,optimum[2,],
     col = "red", type = "l",ylim = c(0,1),
     ylab = "",
     xlab = "")
par(new = T)
plot(seqSx,optimum[3,],
     col = "green", type = "l",ylim = c(0,1),
     ylab = "",
     xlab = "")

legend("topleft", lty = c(1,1,1), col = c("blue", "red", "green"), legend = c("Bayes", "Sample Mean", "Constant"))
```



########
########
# Tried Rebecca's Code
########
########



```{r, cache=TRUE}
# set seed 
set.seed(123)
# data
sum_x = 1
n = 30
# prior parameters
a = 0.05; b = 1
# posterior parameters
an = a + sum_x
bn = b + n - sum_x
th = seq(0,1,length.out = 100)
like = dbeta(th, sum_x+1,n-sum_x+1)
prior = dbeta(th,a,b)
post = dbeta(th,sum_x+a,n-sum_x+b)
```

We now consider the loss function. 
```{r,cache=TRUE}
# compute the loss given theta and c 
loss_function = function(theta, c){
  if (c < theta){
    return(10*abs(theta - c))
  } else{
    return(l = abs(theta - c))
  }
}
```



We now write a function **posterior_risk** which is a function of c, parameters a_prior and b_prior for the prior distribution of $\theta$, the summation of $x_i$ sum_x, the number of observations n, and also the number of random draws s. 
```{r}
# compute the posterior risk given c 
# s is the number of random draws 
posterior_risk = function(c, a_prior, b_prior, sum_x, n, s = 30000){
  # randow draws from beta distribution 
  a_post = a_prior + sum_x
  b_post = b_prior + n - sum_x
  theta = rbeta(s, a_post, b_post)
  loss <- apply(as.matrix(theta),1,loss_function,c)
  # average values from the loss function
  risk = mean(loss)
}
# a sequence of c in [0, 0.5]
c = seq(0, 0.5, by = 0.01)
post_risk <- apply(as.matrix(c),1,posterior_risk, a, b, sum_x, n)
head(post_risk)
```

We then look at the Posterior expected loss (posterior risk) for disease prevelance versus c. 
```{r, cache=TRUE}
# plot posterior risk against c 
plot(c, post_risk, type = 'l', col='blue', 
    lwd = 3, ylab ='p(c, x)' )
# minimum of posterior risk occurs at c = 0.08
(c[which.min(post_risk)])
```

We have reproduced Figure 1, and shown that the minimum of posterior risk occurs at $c = 0.08.$

# Task 2 

Now we perform a sensitivity analysis for the prior assumption on $\theta$.

We set $a  = 0.05, 1, 0.05$ and $b = 1, 2, 10$.

If we have different values of $a,b$, the posterior risk is minimized at different values of $c$. The optimal c depends on not only the data, but also the prior setting.  

```{r,cache=TRUE}
# set prior
as = c(0.05, 1, 0.05); bs = c(1, 1, 10)
# initialize posterior risk
post_risk = matrix(NA, 3, length(c))
# for each pair of a and b, compute the posterior risks
for (i in 1:3){
  a_prior = as[i]
  b_prior = bs[i]
  
  post_risk[i,] = apply(as.matrix(c), 1, posterior_risk, a_prior, b_prior, sum_x, n)
}
# plot the posterior risk (for each prior setting)
plot(c, post_risk[1,], type = 'l', col='blue', lty = 1, yaxt = "n", ylab = "p(c, x)")
par(new = T)
plot(c, post_risk[2,], type = 'l', col='red', lty = 2, yaxt = "n", ylab = "")
par(new = T)
plot(c, post_risk[3,], type = 'l', lty = 3, yaxt = "n", ylab = "")
legend("bottomright", lty = c(1,2,3), col = c("blue", "red", "black"), 
       legend = c("a = 0.05 b = 1", "a = 1 b = 1", "a = 0.05 b = 5"))
```

Remark: There is a more automated solution but this is one of most simple solutions and is completely correct. 

# Task 3

Consider the Bayes procedure ($c\approx 0.08$), $c=\bar{x}, c=0.1.$ Reproduce Figure 2. Explain your findings. 

The Bayes procedure always picks c to be a little bigger than $\bar{x}$.

```{r}
# find the sum of the x's
sum_xs = seq(0, 30)
# initialize the minimum c
min_c = matrix(NA, 3, length(sum_xs))
# find_optimal_C finds the optimal c under the Bayes procedure
# function of sum of x, parameters for prior, number of observations, and number of random draws 
find_optimal_C <- function(sum_x, a_prior, b_prior, n, s = 500){
  c = seq(0, 1, by = 0.01)
  post_risk =  apply(as.matrix(c), 1, posterior_risk, a_prior, b_prior, sum_x, n, s)
  c[which.min(post_risk)]
}
min_c[1,] = apply(as.matrix(sum_xs), 1, find_optimal_C, a, b, n)
# find optimal c under sample mean
min_c[2,] = (sum_xs)/n
# constant c 
min_c[3,] = 0.1
# plot Bayes procedure, sample mean, and constant 
plot(sum_xs, min_c[1,], col='blue',type = 'o',pch = 16, 
     ylab = "resources allocated", xlab = 'observed number of diseased cases',
     ylim = c(0,1))
par(new = T)
plot(sum_xs, min_c[2,], type = 'o', col='green', 
     pch = 16, ylab = "", xlab = '', ylim = c(0,1))
par(new = T)
plot(sum_xs, min_c[3,], type = 'o',col = 'red',
     pch = 16, ylab = "", xlab = '', ylim = c(0,1))
legend("topleft", lty = c(1,1,1), pch = c(16,16,16),
       col = c("blue", "green", "red"),
       legend = c("Bayes", "Sample mean", "constant"))
```


# Task 4

For all $\theta$, the Bayes procedure has the lower frequentist risk than the sample mean. 
```{r, cache=TRUE}
thetas = seq(0, 1, by=0.1)
# frequentist risk for the 3 estimators given a theta
frequentist_risk = function(theta){
  sum_xs = rbinom(100, 30, theta)
  Bayes_optimal = apply(as.matrix(sum_xs), 1, find_optimal_C, a, b, n, s = 100)
  mean_c = sum_xs / 30
  
  loss1 = apply(as.matrix(Bayes_optimal), 1, loss_function, theta = theta)
  loss2 = apply(as.matrix(mean_c), 1, loss_function, theta = theta )
  risk1 = mean(loss1)
  risk2 = mean(loss2)
  risk3 = loss_function(theta, 0.1)
  return(c(risk1, risk2, risk3))
}
# given a sequance a theta, compute frequentist risk for each theta
R = apply(as.matrix(thetas), 1, frequentist_risk)
# plot
plot(thetas, R[1,], col='blue', type = "l", 
     ylab = "frequentist risk", xlab = 'theta',ylim = c(0,1))
par(new = T)
plot(thetas, R[2,], type = 'l', col='green', 
     ylab = "", xlab = '', ylim = c(0,1))
par(new = T)
plot(thetas, R[3,], type = 'l',col = 'red',
     ylab = "", xlab = '', ylim = c(0,1))
legend("topright", lty = c(1,1,1), col = c("blue", "green", "red"),
       legend = c("Bayes", "Sample mean", "constant"))
```

Please see a few remarks about Task 4 that will help you with interpreting the plot. 
\begin{enumerate}
\item If you zoom into see the plot for Task 4, you will notice that the Bayes risk is not always smaller than the sample mean. Specifically, the issue is occuring around $\theta = 0$ and $\theta = 1.$
\item One observation that we can make is that when $x$ is very small (say 0), Bayes estimator tends to overestimate $\theta$ and hence sample mean has lower risk. What other observations can you make? 
\end{enumerate}

I am including some code that Xu Chen has written that is much faster, where the resulting plot is more clear. 

```{r}
# code by Xu Chen
loss <- function(theta, c){
  if (c >= theta) {
    return(c - theta)
  } else {
    return(10*(theta - c))
  }
}
delta1 <- function(x){
  return(rep(0.1,length(x)))
}
delta2 <- function(x){
  return(x/30)
}
delta3 <- function(x, a = 0.05, b = 1){
  a.post <- a + x
  b.post <- b + 30 - x
  c <- seq(0,1,0.01)
  theta <- matrix(rbeta(1e4*length(c), a.post, b.post), 
                  nrow = 1e4, ncol = length(c))
  
  return(c[which.min(sapply(c, function(u) mean(sapply(theta[,as.integer(100*u+1)], loss, c = u))))])
}
risk <- function(theta, c){
  return(sum(dbinom(x = 0:30, size = 30, prob = theta) * sapply(c, loss, theta = theta)))
}
theta.grid <- seq(0,1,0.01)
x <- 0:30
c3 <- sapply(x, delta3)
plot(theta.grid, sapply(theta.grid, risk, c3), 
     ylim = c(0,1), type = 'l', col = 'red', xlab = expression(theta), ylab = 'risk')
c1 <- delta1(x)
points(theta.grid, sapply(theta.grid, risk, c1), 
       ylim = c(0,1), type = 'l')
c2 <- delta2(x)
points(theta.grid, sapply(theta.grid, risk, c2), 
       ylim = c(0,1), type = 'l', col='green')
legend('topright', legend = c('Bayes', 'sample mean', 'constant'), 
       col = c('red', 'green', 'black'), lty = 1)
```
